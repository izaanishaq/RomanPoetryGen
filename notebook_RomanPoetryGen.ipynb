{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trained model using Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T15:47:29.954525Z",
     "iopub.status.busy": "2025-02-13T15:47:29.954233Z",
     "iopub.status.idle": "2025-02-13T15:47:38.958922Z",
     "shell.execute_reply": "2025-02-13T15:47:38.958196Z",
     "shell.execute_reply.started": "2025-02-13T15:47:29.954486Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unidecode\n",
      "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.2.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nltk) (1.17.0)\n",
      "Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: unidecode\n",
      "Successfully installed unidecode-1.3.8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install unidecode nltk\n",
    "import nltk \n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from unidecode import unidecode\n",
    "from tqdm import tqdm\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T16:28:29.024606Z",
     "iopub.status.busy": "2025-02-13T16:28:29.024299Z",
     "iopub.status.idle": "2025-02-13T16:28:38.523021Z",
     "shell.execute_reply": "2025-02-13T16:28:38.522310Z",
     "shell.execute_reply.started": "2025-02-13T16:28:29.024586Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 36\n",
      "Number of sequences: 295851\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/kaggle/input/poetrydataset/Roman-Urdu-Poetry.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "text = \" \".join(df['Poetry'].apply(lambda x: unidecode(x).lower()))\n",
    "\n",
    "# Character-Level Tokenization\n",
    "chars = sorted(set(text))\n",
    "vocab = {char: i + 2 for i, char in enumerate(chars)}  # +2 for <unk> and <pad>\n",
    "vocab['<unk>'], vocab['<pad>'] = 0, 1\n",
    "idx_to_char = {i: char for char, i in vocab.items()}\n",
    "\n",
    "seq_len, stride = 100, 3\n",
    "indices = [vocab.get(char, vocab['<unk>']) for char in text]\n",
    "inputs = [torch.tensor(indices[i:i + seq_len]) for i in range(0, len(indices) - seq_len, stride)]\n",
    "targets = [torch.tensor(indices[i + seq_len]) for i in range(0, len(indices) - seq_len, stride)]\n",
    "\n",
    "dataset = TensorDataset(pad_sequence(inputs, batch_first=True, padding_value=vocab['<pad>']), torch.tensor(targets))\n",
    "train_dataloader = DataLoader(dataset, batch_size=3072, shuffle=True, drop_last=True)\n",
    "\n",
    "print(f\"Vocabulary size: {len(vocab)}\")\n",
    "print(f\"Number of sequences: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T16:26:31.822899Z",
     "iopub.status.busy": "2025-02-13T16:26:31.822594Z",
     "iopub.status.idle": "2025-02-13T16:26:31.844158Z",
     "shell.execute_reply": "2025-02-13T16:26:31.843528Z",
     "shell.execute_reply.started": "2025-02-13T16:26:31.822876Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "embedding = nn.Embedding(len(vocab), 128, padding_idx=vocab['<pad>']).to(device)\n",
    "lstm = nn.LSTM(128, 256, 3, batch_first=True, dropout=0.2).to(device)\n",
    "linear = nn.Linear(256, len(vocab)).to(device)\n",
    "\n",
    "def forward_pass(inputs, hidden=None):\n",
    "    lstm_out, hidden = lstm(embedding(inputs), hidden)\n",
    "    return linear(lstm_out[:, -1, :]), hidden\n",
    "\n",
    "optimizer = torch.optim.AdamW(list(embedding.parameters()) + list(lstm.parameters()) + list(linear.parameters()), lr=0.003, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=vocab['<pad>'])\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T16:06:42.557514Z",
     "iopub.status.busy": "2025-02-13T16:06:42.557110Z",
     "iopub.status.idle": "2025-02-13T16:14:35.664265Z",
     "shell.execute_reply": "2025-02-13T16:14:35.663355Z",
     "shell.execute_reply.started": "2025-02-13T16:06:42.557486Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 96/96 [00:47<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Avg Loss: 2.5141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 96/96 [00:46<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Avg Loss: 1.9331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 96/96 [00:47<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Avg Loss: 1.7538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 96/96 [00:47<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Avg Loss: 1.6574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 96/96 [00:47<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Avg Loss: 1.5897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 96/96 [00:47<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Avg Loss: 1.5378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 96/96 [00:47<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Avg Loss: 1.5008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 96/96 [00:47<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Avg Loss: 1.4719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 96/96 [00:47<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Avg Loss: 1.4471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 96/96 [00:47<00:00,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Avg Loss: 1.4262\n",
      "Training complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 10):\n",
    "    total_loss = 0\n",
    "    hidden = (torch.zeros(3, 3072, 256).to(device), torch.zeros(3, 3072, 256).to(device))\n",
    "\n",
    "    for inputs, targets in tqdm(train_dataloader, desc=f\"Epoch {epoch}\"):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        hidden = (hidden[0].detach(), hidden[1].detach())\n",
    "        outputs, hidden = forward_pass(inputs, hidden)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(list(embedding.parameters()) + list(lstm.parameters()) + list(linear.parameters()), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch}, Avg Loss: {avg_loss:.4f}\")\n",
    "    scheduler.step(avg_loss)\n",
    "\n",
    "torch.save({\n",
    "    'embedding': embedding.state_dict(),\n",
    "    'lstm': lstm.state_dict(),\n",
    "    'linear': linear.state_dict(),\n",
    "}, 'poetGenModel.pth')\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T16:46:22.336612Z",
     "iopub.status.busy": "2025-02-13T16:46:22.336261Z",
     "iopub.status.idle": "2025-02-13T16:46:22.515506Z",
     "shell.execute_reply": "2025-02-13T16:46:22.514607Z",
     "shell.execute_reply.started": "2025-02-13T16:46:22.336585Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wo jo tum ham raha aada hai \n",
      "ab kahin jalva-e-dastan ka \n",
      "tasko ki tum karte hain gard-e-be-nigahon ko kahte hain \n",
      "ab thikani hai jin se baar ki kama.i hai \n",
      "aata salam ke dariya di jaa.e \n",
      "halyaza jo bol ke dil se yaaro saa \n",
      "khata juston ki mil gaya hai din va b\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = 'poetGenModel.pth'\n",
    "\n",
    "embedding = nn.Embedding(len(vocab), 128, padding_idx=vocab['<pad>']).to(device)\n",
    "lstm = nn.LSTM(128, 256, 3, batch_first=True, dropout=0.2).to(device)\n",
    "linear = nn.Linear(256, len(vocab)).to(device)\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=True)\n",
    "embedding.load_state_dict(checkpoint['embedding'])\n",
    "lstm.load_state_dict(checkpoint['lstm'])\n",
    "linear.load_state_dict(checkpoint['linear'])\n",
    "\n",
    "embedding.eval()\n",
    "lstm.eval()\n",
    "linear.eval()\n",
    "\n",
    "seed_text = \"wo jo tum \"\n",
    "gen_len = 250  \n",
    "temperature = 0.85 \n",
    "\n",
    "seed_text = unidecode(seed_text).lower()\n",
    "indices = [vocab.get(char, vocab['<unk>']) for char in seed_text] \n",
    "input_tensor = torch.tensor(indices).unsqueeze(0).to(device)\n",
    "hidden = init_hidden(1)\n",
    "\n",
    "generated_indices = indices\n",
    "with torch.no_grad():\n",
    "    for _ in range(gen_len):\n",
    "        outputs, hidden = forward_pass(input_tensor, hidden)\n",
    "        output = outputs / temperature\n",
    "        probs = torch.softmax(output, dim=-1)\n",
    "        pred_idx = torch.multinomial(probs, num_samples=1).item()\n",
    "        generated_indices.append(pred_idx)\n",
    "        input_tensor = torch.tensor([[pred_idx]]).to(device)\n",
    "\n",
    "generated_text = ''.join([idx_to_char[i] for i in generated_indices]) \n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6632614,
     "sourceId": 10702483,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
